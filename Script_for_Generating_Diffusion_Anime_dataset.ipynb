{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6118,"status":"ok","timestamp":1764350611511,"user":{"displayName":"Oluwatomisin Badmus","userId":"09280461038159943489"},"user_tz":300},"id":"X2e_-yLXOKfa","outputId":"1455d8ac-8399-4c51-b22f-14f0228e30cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (0.35.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers) (8.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers) (3.20.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers) (2.32.4)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers) (0.7.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers) (11.3.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: tokenizers\u003c=0.23.0,\u003e=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch\u003e=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n","Requirement already satisfied: pyarrow\u003e=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill\u003c0.3.9,\u003e=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess\u003c0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec\u003c=2025.3.0,\u003e=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (2025.3.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet\u003c2.0.0,\u003e=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (3.13.2)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ediffusers) (3.4.4)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ediffusers) (3.11)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ediffusers) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ediffusers) (2025.11.12)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (75.2.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (1.14.0)\n","Requirement already satisfied: networkx\u003e=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=2.0.0-\u003eaccelerate) (3.5.0)\n","Requirement already satisfied: zipp\u003e=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata-\u003ediffusers) (3.23.0)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas-\u003edatasets) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas-\u003edatasets) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas-\u003edatasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (2.6.1)\n","Requirement already satisfied: aiosignal\u003e=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (1.4.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (25.4.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (1.8.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (6.7.0)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (0.4.1)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003c=2025.3.0,\u003e=2023.1.0-\u003edatasets) (1.22.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas-\u003edatasets) (1.17.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch\u003e=2.0.0-\u003eaccelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch\u003e=2.0.0-\u003eaccelerate) (3.0.3)\n"]}],"source":["!pip install diffusers transformers accelerate datasets huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"tGX74YJKOMxF","outputId":"6d2a7e75-772d-40c6-f55f-0fb5238c2108"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59c864dcc9804ef3819f5d61ebd04706","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/286 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b58ed24b8ec54f6e9935342cd1edaedc","version_major":2,"version_minor":0},"text/plain":["data/train-00000-of-00002.parquet:   0%|          | 0.00/523M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bee07dc2abf5463b9b61ec4bbba82079","version_major":2,"version_minor":0},"text/plain":["data/train-00001-of-00002.parquet:   0%|          | 0.00/562M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import login\n","from datasets import load_dataset\n","\n","dataset = load_dataset(\"kevinbenoy/anime_random_images\", split = \"train\")\n","\n","\n","len(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50DP8aPTORlj"},"outputs":[],"source":["import torch\n","print(torch.cuda.is_available())\n","print(torch.cuda.device_count())\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mYETsSdeOSQS"},"source":["## Prepare Dataset for Training\n","\n","### Subtask:\n","The loaded dataset will be preprocessed for training the diffusion model. This involves resizing images to a standard dimension, normalizing pixel values, and converting them into PyTorch tensors.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ctFJ4NcjOW6Y"},"outputs":[],"source":["from torchvision import transforms\n","\n","preprocess = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5]*3, [0.5]*3),\n","])\n","\n","def transform(examples):\n","    examples[\"pixel_values\"] = [preprocess(img.convert(\"RGB\")) for img in examples[\"image\"]]\n","    return examples\n","\n","dataset = dataset.with_transform(transform)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EgxvnaTkOdyQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n","UNet2DModel initialized successfully.\n","DDPMScheduler initialized successfully.\n"]}],"source":["from diffusers import UNet2DModel, DDPMScheduler\n","\n","# Initialize the UNet2DModel\n","model = UNet2DModel(\n","    sample_size=64,\n","    in_channels=3,\n","    out_channels=3,\n","    layers_per_block=2,\n","    block_out_channels=(64, 128, 128, 256),\n",")\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")\n","\n","\n","print(\"UNet2DModel initialized successfully.\")\n","\n","# Initialize the DDPMScheduler\n","scheduler = DDPMScheduler(num_train_timesteps=400)\n","print(\"DDPMScheduler initialized successfully.\")\n"]},{"cell_type":"markdown","metadata":{"id":"eXffi-9POlYl"},"source":["## Configure and Train Diffusion Model\n","\n","### Subtask:\n","Configure training parameters and execute the training loop for the diffusion model. This will involve setting up the optimizer, learning rate, and a limited number of training steps. Acknowledge the small dataset size and potential lack of GPU.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GsjJYFjPOlHh"},"outputs":[{"name":"stdout","output_type":"stream","text":["custom_collate_fn defined successfully.\n"]}],"source":["import torch\n","\n","def custom_collate_fn(batch):\n","    # Extract 'pixel_values' from each item in the batch\n","    pixel_values = [item[\"pixel_values\"] for item in batch]\n","    # Stack them into a single tensor\n","    return torch.stack(pixel_values)\n","\n","print(\"custom_collate_fn defined successfully.\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jrHLhhNUOpsA"},"outputs":[],"source":["\n","\n","# import torch\n","# from torch.utils.data import DataLoader\n","# from torch.optim import AdamW\n","# from tqdm import tqdm\n","# from torch.cuda.amp import autocast, GradScaler\n","\n","# scaler = GradScaler()\n","\n","# # 2. Define training parameters\n","# num_epochs = 50\n","# batch_size = 32\n","# learning_rate = 1e-4\n","\n","# # 3. Create a DataLoader from the preprocessed dataset, using the custom collate function\n","# # train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n","# train_dataloader = DataLoader(\n","#     dataset,\n","#     batch_size=batch_size,\n","#     shuffle=True,\n","#     num_workers=4,      # or 8 if Colab Pro\n","#     pin_memory=True,\n","#     persistent_workers=True,\n","#     collate_fn=custom_collate_fn)\n","\n","\n","# # 4. Initialize the AdamW optimizer for the model\n","# optimizer = AdamW(model.parameters(), lr=learning_rate)\n","\n","# # 5. Move the model to the 'cpu' device\n","# model.to(device)\n","\n","# # 6. Implement the training loop\n","# model.train() # Set model to training mode\n","\n","# print(f\"Starting training for {num_epochs} epochs on {device}...\")\n","\n","# for epoch in range(num_epochs):\n","#     epoch_loss = 0\n","#     pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\", leave=False)\n","\n","#     for batch in pbar:\n","#         clean_images = batch.to(device)\n","\n","#         noise = torch.randn(clean_images.shape, device=device)\n","#         timesteps = torch.randint(0, scheduler.config.num_train_timesteps, (clean_images.shape[0],), device=device)\n","\n","#         noisy_images = scheduler.add_noise(clean_images, noise, timesteps)\n","\n","#         with torch.cuda.amp.autocast():\n","#             noise_pred = model(noisy_images, timesteps).sample\n","#             loss = torch.nn.functional.mse_loss(noise_pred, noise)\n","\n","#         optimizer.zero_grad()\n","#         scaler.scale(loss).backward()\n","#         scaler.step(optimizer)\n","#         scaler.update()\n","\n","#     # for batch in pbar:\n","#     #     clean_images = batch.to(device)\n","#     #     noise = torch.randn(clean_images.shape).to(device)\n","\n","#     #     timesteps = torch.randint(\n","#     #         0, scheduler.config.num_train_timesteps, (clean_images.shape[0],)\n","#     #     ).to(device)\n","\n","#     #     noisy_images = scheduler.add_noise(clean_images, noise, timesteps)\n","#     #     noise_pred = model(noisy_images, timesteps).sample\n","#     #     loss = torch.nn.functional.mse_loss(noise_pred, noise)\n","\n","#     #     optimizer.zero_grad()\n","#     #     loss.backward()\n","#     #     optimizer.step()\n","\n","#         epoch_loss += loss.item()\n","\n","#         # Show current batch loss\n","#         pbar.set_postfix({\"batch_loss\": loss.item()})\n","\n","#     print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_dataloader):.4f}\")\n","\n","# print(\"Training complete.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zqBSsP6lOpd6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1862396663.py:28: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  scaler = GradScaler('cuda') # Updated to use torch.amp.GradScaler with device\n"]},{"name":"stdout","output_type":"stream","text":["Using device: cpu\n","Starting training for 50 epochs...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1:   0%|          | 0/625 [00:00\u003c?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n","/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn(\n","Epoch 1: 100%|██████████| 625/625 [2:11:42\u003c00:00, 12.64s/it, loss=0.0763]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50, Avg Loss: 0.1146\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2:  14%|█▍        | 86/625 [18:17\u003c1:52:29, 12.52s/it, loss=0.0949]"]}],"source":["from torch.utils.data import DataLoader\n","from torch.amp import autocast, GradScaler # Updated import\n","from tqdm import tqdm\n","import torch\n","from torch.optim import AdamW\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")\n","\n","model.to(device) # Moved model to the correct device\n","model.train()\n","\n","num_epochs = 50\n","batch_size = 32\n","learning_rate = 1e-4\n","\n","train_dataloader = DataLoader(\n","    dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=4,\n","    pin_memory=True,\n","    persistent_workers=True,\n","    collate_fn=custom_collate_fn\n",")\n","\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","scaler = GradScaler('cuda') # Updated to use torch.amp.GradScaler with device\n","\n","\n","print(f\"Starting training for {num_epochs} epochs...\")\n","\n","for epoch in range(num_epochs):\n","    epoch_loss = 0\n","    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n","\n","    for batch in pbar:\n","        clean_images = batch.to(device)\n","\n","        noise = torch.randn_like(clean_images)\n","        timesteps = torch.randint(\n","            0, scheduler.config.num_train_timesteps,\n","            (clean_images.size(0),), device=device\n","        )\n","\n","        noisy_images = scheduler.add_noise(clean_images, noise, timesteps)\n","\n","        with autocast(device_type='cuda'): # Updated to use torch.amp.autocast with device_type\n","            noise_pred = model(noisy_images, timesteps).sample\n","            loss = torch.nn.functional.mse_loss(noise_pred, noise)\n","\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        epoch_loss += loss.item()\n","        pbar.set_postfix({\"loss\": loss.item()})\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Avg Loss: {epoch_loss/len(train_dataloader):.4f}\")\n","\n","print(\"Training complete.\")"]},{"cell_type":"markdown","metadata":{"id":"dNXNj5qGOpMN"},"source":["\n","## Save Trained Model to Hugging Face\n","\n","### Subtask:\n","Authenticate your Hugging Face account and save the trained diffusion model to a new repository on your Hugging Face profile.\n","\n","\n","**Reasoning**:\n","I will import `create_repo` from `huggingface_hub`, call `login()` to authenticate, define a `repo_id`, create the repository using `create_repo`, and then save the `model` and `scheduler` to that repository.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3bDQBS2O5H8"},"outputs":[],"source":["\n","from huggingface_hub import login, create_repo\n","\n","# # Log in to Hugging Face (you will be prompted to enter your token)\n","# login()\n","\n","# Define your repository ID\n","# Replace 'your-username' with your actual Hugging Face username\n","repo_id = \"Tomisin05/unconditional-anime-diffusion-model\"\n","\n","# Create the repository on Hugging Face\n","create_repo(repo_id, exist_ok=True, repo_type=\"model\")\n","print(f\"Hugging Face repository '{repo_id}' created or already exists.\")\n","\n","# Save the trained model and scheduler to the repository\n","model.push_to_hub(repo_id)\n","scheduler.push_to_hub(repo_id)\n","\n","print(\"Model and scheduler saved to Hugging Face repository.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s61_0WrfO8mI"},"outputs":[],"source":["from diffusers import DDPMPipeline\n","import torch\n","\n","pipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n","\n","# Move model to GPU if supported\n","pipeline.to(\"cuda\")  # Or change to \"cpu\" if your model is CPU-trained\n","\n","num_images_to_generate = 10\n","batch_size = 8\n","\n","test_images = []\n","\n","print(f\"Starting generation of {num_images_to_generate} images...\")\n","\n","for i in range(0, num_images_to_generate, batch_size):\n","    with torch.no_grad():\n","        images_batch_output = pipeline(\n","            batch_size=batch_size,\n","            output_type=\"pil\",\n","            num_inference_steps=400\n","        )\n","    test_images.extend(images_batch_output.images) # Access the .images attribute\n","\n","    print(f\"Generated {len(test_images)} / {num_images_to_generate} images...\")\n","\n","print(f\"Successfully generated {len(test_images)} images.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZIj0pFfO_NY"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Display a few of the generated images\n","print(f\"Displaying {max(5, len(test_images))} sample generated images:\")\n","\n","plt.figure(figsize=(10, 2))\n","for i, image in enumerate(test_images[:16]):\n","    plt.subplot(1, 16, i + 1)\n","    plt.imshow(image)\n","    plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oi6f15ZehwXG"},"outputs":[],"source":["from diffusers import DDPMPipeline\n","\n","pipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n","\n","pipeline.push_to_hub(\n","    \"Tomisin05/unconditional-anime-diffusion-model\",\n","    commit_message=\"Upload trained DDPM pipeline.\"\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"T_jj-9aBPCVC"},"source":["## Generate 20,000 Images\n","\n","### Subtask:\n","Using the trained diffusion model, generate 20,000 new images. The generation process will be configured to ensure diversity and quality as much as possible, given the model's training limitations.\n","\n","\n","**Reasoning**:\n","I will import necessary libraries, instantiate the DDPM pipeline from the previously trained model and scheduler, then iterate to generate 20,000 images in batches, collecting them in a list.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cQ-uUdVQg4D-"},"outputs":[],"source":["import os\n","import torch\n","from diffusers import DDPMPipeline\n","from datasets import Dataset, Image\n","\n","# Create pipeline\n","pipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n","\n","# Total images\n","num_images_to_generate = 21000\n","batch_size = 8\n","chunk_size = 100  # how often to push to HuggingFace\n","\n","save_dir = \"generated_images\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# Hugging Face repo\n","hf_repo = \"Tomisin05/generated-anime-images\"\n","\n","print(f\"Starting generation of {num_images_to_generate} images...\")\n","\n","global_count = 0  # total images generated so far\n","current_chunk_files = []  # list of files waiting to be uploaded\n","\n","for i in range(0, num_images_to_generate, batch_size):\n","\n","    # generate batch of images\n","    with torch.no_grad():\n","        images = pipeline(\n","            batch_size=batch_size,\n","            output_type=\"pil\",\n","            num_inference_steps=400\n","        ).images\n","\n","    # save images and track filenames\n","    for img in images:\n","        filename = f\"{save_dir}/{global_count}.png\"\n","        img.save(filename)\n","        current_chunk_files.append(filename)\n","        global_count += 1\n","\n","    # If 100 images collected → push to hub\n","    if len(current_chunk_files) \u003e= chunk_size:\n","        print(f\"Pushing {len(current_chunk_files)} images to Hugging Face...\")\n","\n","        # Build HF Dataset just for this chunk\n","        ds = Dataset.from_dict({\"image\": current_chunk_files}).cast_column(\"image\", Image())\n","\n","        ds.push_to_hub(\n","            hf_repo,\n","            commit_message=f\"Upload {global_count} images\",\n","            private=True\n","        )\n","\n","        print(f\"Uploaded {len(current_chunk_files)} images\")\n","\n","        # Clear list\n","        current_chunk_files = []\n","\n","# After loop: upload any remaining images\n","if current_chunk_files:\n","    print(f\"Pushing final {len(current_chunk_files)} images...\")\n","    ds = Dataset.from_dict({\"image\": current_chunk_files}).cast_column(\"image\", Image())\n","    ds.push_to_hub(\n","        hf_repo,\n","        commit_message=f\"Final upload - total {global_count}\",\n","        private=True\n","    )\n","\n","print(f\"Done! Total uploaded: {global_count} images.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJCKJuqgg4AO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33Lo6j-Vg39Q"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHqS4EnUg35i"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGj1CP_Pg3uC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ECC6DLdO_DR"},"outputs":[],"source":["\n","\n","# import os\n","\n","# # Create a DDPMPipeline object from the trained model and scheduler\n","# pipeline = DDPMPipeline(unet=model, scheduler=scheduler)\n","\n","# # Define the total number of images to generate and a suitable batch_size\n","# num_images_to_generate = 21000\n","# batch_size = 8  # Adjust based on memory availability\n","\n","# os.makedirs(\"generated_images\", exist_ok=True)\n","\n","\n","# print(f\"Starting generation of {num_images_to_generate} images...\")\n","\n","# count = 0\n","# for i in range(0, num_images_to_generate, batch_size):\n","#     with torch.no_grad():\n","#         images = pipeline( batch_size=batch_size,\n","#             output_type=\"pil\",\n","#             num_inference_steps=400  ).images\n","#     for img in images:\n","#         img.save(f\"generated_images/{count}.png\")\n","#         count += 1\n","\n","\n","# # Print a confirmation message\n","# print(f\"Successfully generated {count} images.\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvBBATTIPI62"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ORrOEXrEPL49"},"source":["\n","## Display Sample Generated Images\n","\n","### Subtask:\n","Display a few of the recently generated images from the `generated_images` list to visualize the current output of the diffusion model.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mmbRkD57PPdZ"},"outputs":[],"source":["\n","import matplotlib.pyplot as plt\n","\n","import glob\n","from PIL import Image\n","\n","sample_files = sorted(glob.glob(\"generated_images/*.png\"))[:5]\n","images = [Image.open(f) for f in sample_files]\n","\n","# Display a few of the generated images\n","print(f\"Displaying {min(5, len(images))} sample generated images:\")\n","\n","plt.figure(figsize=(10, 2))\n","for i, image in enumerate(images):\n","    plt.subplot(1, 5, i + 1)\n","    plt.imshow(image)\n","    plt.axis('off')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"yWSvs7JGPSyD"},"source":["\n","## Create and Push Generated Image Dataset to Hugging Face\n","\n","### Subtask:\n","The previously generated images will be compiled into a new Hugging Face dataset. This dataset will then be uploaded to a new repository on your Hugging Face profile, making it accessible for future use.\n","\n","\n","**Reasoning**:\n","I will import the `Dataset` class, create a dictionary from the `generated_images`, instantiate a Hugging Face Dataset, define a new repository ID, and then push the dataset to the Hugging Face Hub.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_RzIkm6PVXD"},"outputs":[],"source":["import datasets\n","from datasets import Dataset, Image\n","\n","\n","ds = Dataset.from_dict(\n","    {\"image\": [f\"generated_images/{i}.png\" for i in range(global_count)]}\n",").cast_column(\"image\", Image())\n","\n","ds.push_to_hub(\"Tomisin05/generated-anime-images\", commit_message=f\"Upload {global_count}  images\", private=True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtge1U5zniUu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOmWwUwxniRG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bEeuZlhfniMY"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0785c369012e469e9c974d1a6790ac91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b13affd177f432c974e0cde8728bdf9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c9908337000436087f801cdf2c0d648":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48874678c64d4ca4876038f8a9f0e1a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49cc3bd031e64347823e35ba0ddb041d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dc88350730c44e9a91d736466c2b469":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0785c369012e469e9c974d1a6790ac91","max":523039849,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81d3fd530ee74e5cb8567c9e8f2aa3b8","value":523039849}},"4ed7cbcd65c648b48b6c70d2a23facbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5519da45fe9c478e813db3764fc86534":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57b1c026f18d4ae0b0fd3213bb4cd784":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57f622e734c24ee493cbba478a0e9901":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59c864dcc9804ef3819f5d61ebd04706":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_885a9284a69e404d9e4a9abe38f40810","IPY_MODEL_f4d91ef3951d49fab0070f48c527fd87","IPY_MODEL_a9c1ecc6e38a47b4b30842ad9da8e8e2"],"layout":"IPY_MODEL_57b1c026f18d4ae0b0fd3213bb4cd784"}},"60ad1cbd0ff14b28b089c79e8ff6e2cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49cc3bd031e64347823e35ba0ddb041d","placeholder":"​","style":"IPY_MODEL_fc7de9757f804063a28d7234807fbf30","value":" 428M/562M [00:02\u0026lt;00:00, 413MB/s]"}},"6c206e3b9e7f498d8ae99258cf6cde89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d3fd530ee74e5cb8567c9e8f2aa3b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"885a9284a69e404d9e4a9abe38f40810":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c206e3b9e7f498d8ae99258cf6cde89","placeholder":"​","style":"IPY_MODEL_8b468e328fba40aa9df1ba2e2ba97516","value":"README.md: 100%"}},"8b468e328fba40aa9df1ba2e2ba97516":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b6f067e2b7845558831bf9574bc4ec0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a680c1674ce94517bc0a190e7a5cda8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9c1ecc6e38a47b4b30842ad9da8e8e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6d742f67eb840c7a8fbb83dae5cd7e4","placeholder":"​","style":"IPY_MODEL_dba36301ea9c4a8bbb6276f4a8e4bc89","value":" 286/286 [00:00\u0026lt;00:00, 29.6kB/s]"}},"ad82d75d30584a0d89b9aed778b7c4c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b58ed24b8ec54f6e9935342cd1edaedc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c72dc43224af4b1ea0ad080a7f5f2e64","IPY_MODEL_4dc88350730c44e9a91d736466c2b469","IPY_MODEL_c9ac1cadf877429eba9fbccb845759e7"],"layout":"IPY_MODEL_57f622e734c24ee493cbba478a0e9901"}},"bee07dc2abf5463b9b61ec4bbba82079":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2b4f228fb2641e6a33f6ce793c5c5ba","IPY_MODEL_fcf9bf29f03442b3a1ada5631e6d1d34","IPY_MODEL_60ad1cbd0ff14b28b089c79e8ff6e2cf"],"layout":"IPY_MODEL_2b13affd177f432c974e0cde8728bdf9"}},"c64336401aea427b8ad43fc8d87dbf0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c72dc43224af4b1ea0ad080a7f5f2e64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d06cf59a93a54ba08036dfc881c963c6","placeholder":"​","style":"IPY_MODEL_2c9908337000436087f801cdf2c0d648","value":"data/train-00000-of-00002.parquet: 100%"}},"c9ac1cadf877429eba9fbccb845759e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ed7cbcd65c648b48b6c70d2a23facbc","placeholder":"​","style":"IPY_MODEL_c64336401aea427b8ad43fc8d87dbf0d","value":" 523M/523M [00:02\u0026lt;00:00, 301MB/s]"}},"d06cf59a93a54ba08036dfc881c963c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2b4f228fb2641e6a33f6ce793c5c5ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5519da45fe9c478e813db3764fc86534","placeholder":"​","style":"IPY_MODEL_ad82d75d30584a0d89b9aed778b7c4c2","value":"data/train-00001-of-00002.parquet:  76%"}},"d6d742f67eb840c7a8fbb83dae5cd7e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba36301ea9c4a8bbb6276f4a8e4bc89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4d91ef3951d49fab0070f48c527fd87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48874678c64d4ca4876038f8a9f0e1a2","max":286,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f642590328fc4c51b3561068b4b1b1d1","value":286}},"f642590328fc4c51b3561068b4b1b1d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc7de9757f804063a28d7234807fbf30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcf9bf29f03442b3a1ada5631e6d1d34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a680c1674ce94517bc0a190e7a5cda8e","max":561852474,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b6f067e2b7845558831bf9574bc4ec0","value":427672413}}}}},"nbformat":4,"nbformat_minor":0}